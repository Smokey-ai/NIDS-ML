import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.feature_selection import RFECV
from sklearn.model_selection import cross_val_score, StratifiedKFold
from imblearn.over_sampling import SMOTE
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings('ignore')

# -------------------------
# Load datasets
# -------------------------
train_data = pd.read_csv('kdd_train_clean.csv')
test_data = pd.read_csv('kdd_test_clean.csv')

target_column = train_data.columns[-1]

X_train = train_data.drop(columns=[target_column])
y_train = train_data[target_column].copy()
X_test = test_data.drop(columns=[target_column])
y_test = test_data[target_column].copy()

print(f"Training shape: {X_train.shape}, Test shape: {X_test.shape}")

# -------------------------
# Encode categorical features
# -------------------------
categorical_columns = X_train.select_dtypes(include=['object', 'category']).columns
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    combined = pd.concat([X_train[col], X_test[col]], axis=0).astype(str)
    le.fit(combined)
    X_train[col] = le.transform(X_train[col].astype(str))
    X_test[col] = le.transform(X_test[col].astype(str))
    label_encoders[col] = le

# Encode target
target_encoder = None
if y_train.dtype == 'object' or y_test.dtype == 'object':
    target_encoder = LabelEncoder()
    combined_y = pd.concat([y_train, y_test], axis=0).astype(str)
    target_encoder.fit(combined_y)
    y_train = target_encoder.transform(y_train.astype(str))
    y_test = target_encoder.transform(y_test.astype(str))

# -------------------------
# SMOTE for minority classes
# -------------------------
print("\nApplying selective SMOTE to training data...")
class_counts = Counter(y_train)
minority_classes = [cls for cls, count in class_counts.items() if count < 500]
print(f"Classes to oversample (count < 500): {minority_classes}")

if minority_classes:
    smote = SMOTE(sampling_strategy={cls: 500 for cls in minority_classes}, k_neighbors=1, random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
else:
    X_train_res, y_train_res = X_train.copy(), y_train.copy()

print(f"Class distribution after SMOTE: {Counter(y_train_res)}")

# -------------------------
# RFECV for feature selection
# -------------------------
base_estimator = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

rfecv = RFECV(
    estimator=base_estimator,
    step=1,
    cv=StratifiedKFold(3),
    scoring='accuracy',
    n_jobs=-1
)

print("\nRunning RFECV feature selection...")
X_train_selected = rfecv.fit_transform(X_train_res, y_train_res)
X_test_selected = rfecv.transform(X_test)
selected_features = X_train.columns[rfecv.support_]
print(f"Selected {len(selected_features)} features: {list(selected_features)}")

# -------------------------
# Train final Random Forest
# -------------------------
final_rf = RandomForestClassifier(
    n_estimators=300,
    max_depth=None,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1,
    verbose=1,
    oob_score=True,
    criterion='entropy'
)

print("\nTraining final Random Forest...")
final_rf.fit(X_train_selected, y_train_res)
print(f"Out-of-bag score: {final_rf.oob_score_:.4f}")

# -------------------------
# Evaluate
# -------------------------
y_pred = final_rf.predict(X_test_selected)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nðŸŽ¯ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")

# Classification report
if target_encoder:
    target_names = target_encoder.classes_
    print(classification_report(y_test, y_pred, target_names=target_names))
else:
    print(classification_report(y_test, y_pred))

# Confusion matrix visualization
plt.figure(figsize=(12,10))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=False, cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# -------------------------
# Feature importance
# -------------------------
importances = pd.DataFrame({
    'feature': selected_features,
    'importance': final_rf.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(12,6))
sns.barplot(x='importance', y='feature', data=importances.head(20))
plt.title('Top 20 Feature Importances')
plt.show()
